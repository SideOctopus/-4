{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Генерація тексту (https://keras.io/examples/generative/lstm_character_level_text_generation/)"
      ],
      "metadata": {
        "id": "T4xG_PHJaJqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3jvlWzkXYPmA"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file(\n",
        "    \"book.txt\",\n",
        "    origin=\"https://www.gutenberg.org/files/11/11-0.txt\",\n",
        ")\n",
        "with io.open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n",
        "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
        "print(\"Corpus length:\", len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=\"bool\")\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=\"bool\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39-ZOs8iYako",
        "outputId": "07d7142b-4135-47fe-94d1-d34b48d03da9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 164047\n",
            "Total chars: 63\n",
            "Number of sequences: 54669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "metadata": {
        "id": "XdQQNkfIZqqr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "jDXrz9y2Zq-V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
        "    print()\n",
        "    print(\"Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.1, 0.5, 1.0]:\n",
        "        print(\"...Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('...Generating with seed: \"' + sentence + '\"')\n",
        "\n",
        "        for i in range(200):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"...Generated: \", generated)\n",
        "        print(\"-\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMCmRC6-Ztm7",
        "outputId": "8e2db5ea-df6d-45d3-c818-6f9acd4c48ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "855/855 [==============================] - 84s 96ms/step - loss: 4.0258\n",
            "\n",
            "Generating text after epoch: 0\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \" the knave was standing before them, in \"\n",
            "...Generated:  the wand the wand and the ment the ment the med the med and the wand the ment the ment the ment and the ment the was the med and the med and the ment the wand the med the ment and the ment and the med\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" the knave was standing before them, in \"\n",
            "...Generated:  thing and the had thout and there the sand and and not the wastly, “in and and and and the me, and the mownt the madd the wast wast inch the menn on of mown and ther and and the ment even and the jont\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" the knave was standing before them, in \"\n",
            "...Generated:  ming that chench he mupm gechough—hend phely mompo she wown to kling at acher mind by choke, and in!” she wern!” the tabound who _ye to in, and the lelmen med the mornat wor marted alice, “my abd my u\n",
            "-\n",
            "855/855 [==============================] - 74s 87ms/step - loss: 1.9420\n",
            "\n",
            "Generating text after epoch: 1\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \"r ladder?—why, i hadn’t to bring but one\"\n",
            "...Generated:   the mock to                                                                                                                                                                                            \n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"r ladder?—why, i hadn’t to bring but one\"\n",
            "...Generated:   her it coper the mode comememet of calf men have of the was of the par more cimpencomes of chome the moke the moke the moke the mock to see vook of the moke have wwow her have stlome aboked the gryph\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"r ladder?—why, i hadn’t to bring but one\"\n",
            "...Generated:  ping the qurow:   “the gaok the ?” a cho a op mong his of hw spand, the coulder very by, peemmek the cat you, everg vore crimning c’t off the ging ward more ingrh dorrer be for,”  “whent the ken of it\n",
            "-\n",
            "855/855 [==============================] - 68s 79ms/step - loss: 1.8480\n",
            "\n",
            "Generating text after epoch: 2\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \"  “nothing,” said alice.  “nothing _what\"\n",
            "...Generated:   the to the to the to the to the to the to the to the to the to the to the to the to the to the tory the to the to the to the to the to the tould the to the to the the to the to the to the to the to t\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"  “nothing,” said alice.  “nothing _what\"\n",
            "...Generated:   to it the poptain and the fortaid that toofen they seember to as to a groouther my the poor to the tice at the stunden the promately, went all to the tipen the down a shing to alice the was the tally\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"  “nothing,” said alice.  “nothing _what\"\n",
            "...Generated:   tal! deonty sha cale fitour of _! that and head the sas hean the  a cauph her teade: wuchoping they beme frout the fropters of seamgetly: raster, happen as it the tory southed alice upfe, staly thoun\n",
            "-\n",
            "855/855 [==============================] - 66s 77ms/step - loss: 1.8167\n",
            "\n",
            "Generating text after epoch: 3\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \" lizard as she spoke. (the unfortunate l\"\n",
            "...Generated:  eased the catent the at the telate at at the telece at the telece the telece the telece the at the weth and at the teter at the telece the telece the teter the telece the telece the tet at the teter t\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \" lizard as she spoke. (the unfortunate l\"\n",
            "...Generated:  assed could the meare who of a laste at at the weth he the telece the all the sted at the sting teated he sark with at and she the weth are the the the with coulded mock to he it the weth and of at an\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \" lizard as she spoke. (the unfortunate l\"\n",
            "...Generated:  ose to cow o! the with began, weth you it, and comet. annten le, at any the came at here or of they lerted re bet teow, pigh the in achad!” the couldn began tleaded,” the wanted it he and ade and agai\n",
            "-\n",
            "855/855 [==============================] - 66s 77ms/step - loss: 1.8052\n",
            "\n",
            "Generating text after epoch: 4\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \"zes: he only does it to annoy,     becau\"\n",
            "...Generated:  ted out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out out \n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"zes: he only does it to annoy,     becau\"\n",
            "...Generated:  te of the for of the more alice, to out out of the mouse, and the mouse on of the was of the downered out to to would and of the mouse out out: of the mouse of the woulder out out of and vole was of t\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"zes: he only does it to annoy,     becau\"\n",
            "...Generated:  th, ingr _i_ out of bend not iilcangenive pat’m who mouse have goed in and cowncey much _you”eddedony to another little ke to the pauseded,” said this on evere of the mouse of ow, to a!” the mouse, al\n",
            "-\n",
            "855/855 [==============================] - 86s 100ms/step - loss: 1.8086\n",
            "\n",
            "Generating text after epoch: 5\n",
            "...Diversity: 0.1\n",
            "...Generating with seed: \"an and two or three pairs of tiny white \"\n",
            "...Generated:  to to to to to to to to to to to to to to to to to to to to the cook to to to to to the cooked to the mock turtle it at the cook to the mock turtle to to to the mock turtle to to to to to to to the mo\n",
            "-\n",
            "...Diversity: 0.5\n",
            "...Generating with seed: \"an and two or three pairs of tiny white \"\n",
            "...Generated:  to her heade to do her the mock turtle to the croojener: go i staicked to to a .    the mock turtle sition of coner to the hention of the chent. up to the differ to the came go it, say por to s  by th\n",
            "-\n",
            "...Diversity: 1.0\n",
            "...Generating with seed: \"an and two or three pairs of tiny white \"\n",
            "...Generated:  to even wrook to in a right to to deplieded thou﻿chih to “this on the y’s gimeving to herself to remertier durred wan up “own’t q0iting. rem_ resing on to plesse go mouse, er. the for contaws__ scoudi\n",
            "-\n",
            "515/855 [=================>............] - ETA: 35s - loss: 1.8030"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. HF Transformers"
      ],
      "metadata": {
        "id": "ZqBnr68yaMiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers installation\n",
        "#pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "a_YB3p-mn2uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = '''Скажи мені, чому не можу\n",
        "Забути те, чого нема\n",
        "Скажи мені, чому не можу\n",
        "Забути те, що... те, що навколо зима'''\n",
        "classifier(text_1)"
      ],
      "metadata": {
        "id": "HsMBIcuJpHH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = '''Що танцюють на голові\n",
        "Та тримають небо на долонях\n",
        "Що танцюють на голові\n",
        "Та тримають небо на долонях\n",
        "Що танцюють на головах\n",
        "Та тримають небо на долонях\n",
        "Що танцюють на головах\n",
        "Та тримають небо на руках'''\n",
        "classifier(text_2)"
      ],
      "metadata": {
        "id": "nZ6kfDV5pFEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Україномовна модель (використовувалась lb-2 https://huggingface.co/ukr-models/lb-2)"
      ],
      "metadata": {
        "id": "N7uMi6VoE1WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "mHhnoYpLEftJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
      ],
      "metadata": {
        "id": "5vnLGHu0EgW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['''Але стіна твоїх очей\n",
        "Втопить мене в блиску ночей –\n",
        "Дихати не дасть її тепло\n",
        "Темна вода хвилю жене\n",
        "Але мене не дожене\n",
        "Хвиля твоя. Я іду на дно...''',\n",
        "             '''Шукай в телефоні мій слід\n",
        "Цілуй в вікно мої губи\n",
        "Як знак на моєму плечі ти квітка, ти квітка\n",
        "Шукай в телефоні мій слід\n",
        "Цілуй в вікно мої губи\n",
        "Так швидко в моєму житті\n",
        "Так швидко ти квітка''',\n",
        "             '''Гей, чому я, чому я\n",
        "Зупинитися не зміг?\n",
        "Як мене збивають з ніг\n",
        "Знов і знов збивають з ніг\n",
        "Твої зелені очі''',\n",
        "             '''Спи собі сама\n",
        "Коли біля тебе мене нема\n",
        "Спи собі сама\n",
        "Коли біля тебе мене нема\n",
        "Спи собі сама\n",
        "Коли біля тебе мене нема\n",
        "Спи собі сама\n",
        "Коли біля тебе мене нема''',\n",
        "             '''не плач, моє серце, не плач,\n",
        "не муч душу свою картонну,\n",
        "ми ще зустрінемось\n",
        "з того боку кордону.\n",
        "\n",
        "з того боку життя,\n",
        "з того боку державної митниці.\n",
        "ми ще побачимось\n",
        "де-небудь в районі Вінниці.\n",
        "\n",
        "я люблю цю країну\n",
        "навіть без кокаїну,\n",
        "небо це березневе,\n",
        "без тебе, серце, без тебе.\n",
        "\n",
        "кину все, що виніс,\n",
        "перепродам свій бізнес,\n",
        "вийду на берег Дунаю,\n",
        "там і сконаю.''']"
      ],
      "metadata": {
        "id": "SgeRI0izEhxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('ukr-models/lb-2')\n",
        "model = AutoModel.from_pretrained('ukr-models/lb-2')"
      ],
      "metadata": {
        "id": "AbI0vhA0ElQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')"
      ],
      "metadata": {
        "id": "sN2PiD0jEmgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "sFSU2ZyiEnng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
      ],
      "metadata": {
        "id": "wCG3_6KNEoxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence embeddings:\")\n",
        "print(sentence_embeddings)"
      ],
      "metadata": {
        "id": "wcWPgWF6EpuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0], ' : ', classifier(sentences[0]))\n",
        "print(sentences[1], ' : ', classifier(sentences[1]))"
      ],
      "metadata": {
        "id": "vY-BNCZeEqyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Копіювання стилю (https://keras.io/examples/generative/neural_style_transfer/)"
      ],
      "metadata": {
        "id": "0fn3xsfUaNXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.applications import vgg19\n",
        "\n",
        "base_image_path = keras.utils.get_file(\"main.jpg\", \"https://cdn3.whatculture.com/images/2014/01/Tony-Stark.jpg\")\n",
        "style_reference_image_path = keras.utils.get_file(\n",
        "    \"style.jpg\", \"https://assets.xboxservices.com/assets/43/79/4379ece7-a52b-4f6a-93c4-8880683b5f26.jpg?n=Cyberpunk-2077_Gallery-0_1350x759_10.jpg\"\n",
        ")\n",
        "result_prefix = \"paris_generated\"\n",
        "\n",
        "# Weights of the different loss components\n",
        "total_variation_weight = 1e-6\n",
        "style_weight = 1e-6\n",
        "content_weight = 2.5e-8\n",
        "\n",
        "# Dimensions of the generated picture.\n",
        "width, height = keras.utils.load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "metadata": {
        "id": "iHxOExd4aN3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(base_image_path))\n",
        "display(Image(style_reference_image_path))"
      ],
      "metadata": {
        "id": "kAndrhSIbK2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Util function to open, resize and format pictures into appropriate tensors\n",
        "    img = keras.utils.load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = keras.utils.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return tf.convert_to_tensor(img)\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "    # Util function to convert a tensor into a valid image\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
        "    return x\n",
        "\n",
        "def gram_matrix(x):\n",
        "    x = tf.transpose(x, (2, 0, 1))\n",
        "    features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "    gram = tf.matmul(features, tf.transpose(features))\n",
        "    return gram\n",
        "\n",
        "\n",
        "# The \"style loss\" is designed to maintain\n",
        "# the style of the reference image in the generated image.\n",
        "# It is based on the gram matrices (which capture style) of\n",
        "# feature maps from the style reference image\n",
        "# and from the generated image\n",
        "\n",
        "\n",
        "def style_loss(style, combination):\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels**2) * (size**2))\n",
        "\n",
        "\n",
        "# An auxiliary loss function\n",
        "# designed to maintain the \"content\" of the\n",
        "# base image in the generated image\n",
        "\n",
        "\n",
        "def content_loss(base, combination):\n",
        "    return tf.reduce_sum(tf.square(combination - base))\n",
        "\n",
        "\n",
        "# The 3rd loss function, total variation loss,\n",
        "# designed to keep the generated image locally coherent\n",
        "\n",
        "\n",
        "def total_variation_loss(x):\n",
        "    a = tf.square(\n",
        "        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :]\n",
        "    )\n",
        "    b = tf.square(\n",
        "        x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :]\n",
        "    )\n",
        "    return tf.reduce_sum(tf.pow(a + b, 1.25))"
      ],
      "metadata": {
        "id": "t-niN-DabNTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg19.VGG19(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "\n",
        "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
      ],
      "metadata": {
        "id": "16dFxmufbQdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style_layer_names = [\n",
        "    \"block1_conv1\",\n",
        "    \"block2_conv1\",\n",
        "    \"block3_conv1\",\n",
        "    \"block4_conv1\",\n",
        "    \"block5_conv1\",\n",
        "]\n",
        "# The layer to use for the content loss.\n",
        "content_layer_name = \"block5_conv2\"\n",
        "\n",
        "\n",
        "def compute_loss(combination_image, base_image, style_reference_image):\n",
        "    input_tensor = tf.concat(\n",
        "        [base_image, style_reference_image, combination_image], axis=0\n",
        "    )\n",
        "    features = feature_extractor(input_tensor)\n",
        "\n",
        "    # Initialize the loss\n",
        "    loss = tf.zeros(shape=())\n",
        "\n",
        "    # Add content loss\n",
        "    layer_features = features[content_layer_name]\n",
        "    base_image_features = layer_features[0, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    loss = loss + content_weight * content_loss(\n",
        "        base_image_features, combination_features\n",
        "    )\n",
        "    # Add style loss\n",
        "    for layer_name in style_layer_names:\n",
        "        layer_features = features[layer_name]\n",
        "        style_reference_features = layer_features[1, :, :, :]\n",
        "        combination_features = layer_features[2, :, :, :]\n",
        "        sl = style_loss(style_reference_features, combination_features)\n",
        "        loss += (style_weight / len(style_layer_names)) * sl\n",
        "\n",
        "    # Add total variation loss\n",
        "    loss += total_variation_weight * total_variation_loss(combination_image)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "vUiTH-KrbT80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_loss_and_grads(combination_image, base_image, style_reference_image):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(combination_image, base_image, style_reference_image)\n",
        "    grads = tape.gradient(loss, combination_image)\n",
        "    return loss, grads"
      ],
      "metadata": {
        "id": "iNVXPc6_bWr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.SGD(\n",
        "    keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.90\n",
        "    )\n",
        ")\n",
        "\n",
        "base_image = preprocess_image(base_image_path)\n",
        "style_reference_image = preprocess_image(style_reference_image_path)\n",
        "combination_image = tf.Variable(preprocess_image(base_image_path))\n",
        "\n",
        "iterations = 500\n",
        "for i in range(1, iterations + 1):\n",
        "    loss, grads = compute_loss_and_grads(\n",
        "        combination_image, base_image, style_reference_image\n",
        "    )\n",
        "    optimizer.apply_gradients([(grads, combination_image)])\n",
        "    if i % 1 == 0:\n",
        "        print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
        "        img = deprocess_image(combination_image.numpy())\n",
        "        fname = result_prefix + \"_at_iteration_%d.png\" % i\n",
        "        keras.utils.save_img(fname, img)"
      ],
      "metadata": {
        "id": "tEqo5jHwbXnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(result_prefix + \"_at_iteration_500.png\"))"
      ],
      "metadata": {
        "id": "1Fr8ZVaA57TR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}